{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Mô tả dữ liệu MNIST cho bài toán nhận dạng chữ viết tay:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# thư viện này để hiển thị các tấm ảnh\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "# để chọn ngẫu nhiên các tấm ảnh\n",
    "import random\n",
    "import os\n",
    "# để load dữ liệu trong tập mẫu\n",
    "from keras.datasets import mnist\n",
    "from keras.models import load_model\n",
    "from matplotlib import image\n",
    "# các hàm sau để xây dựng mô hình mạng neural\n",
    "# thêm 1 lớp, thêm hàm kích hoạt activation\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.core import Dense,Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dữ liệu trong tập data mnist là 60000 tấm ảnh trắng đen có kích thước là 28X28 pixel\n",
    "# mỗi pixel có giá trị từ 0-255, 0 là màu đen và 255 là màu trắng sáng nhất\n",
    "# các giá trị càng gần với 255 thì càng sáng\n",
    "# xem shape của tập train, sau khi xem thì ta sẽ thấy thông tin x_train shape (60000, 28, 28)\n",
    "# nghĩa là có 60000 tấm ảnh trong tập train, mỗi tấm ảnh có kích thước 28*28\n",
    "(x_train,y_train),(x_test,y_test)=mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"x_train shape\",x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=(9,9)\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    num=random.randint(0,len(x_train))\n",
    "    plt.imshow(x_train[num],cmap='gray',interpolation=None)\n",
    "    plt.title('Class {}'.format(y_train[num]))\n",
    "plt.tight_layout() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train.reshape(60000,784)\n",
    "x_train=x_train.astype('float32')\n",
    "# chuẩn hóa dữ liệu nằm trong khoảng 0-1 nên chia cho 255\n",
    "x_train/=255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=x_test.reshape(10000,784)\n",
    "x_test=x_test.astype('float32')\n",
    "x_test/=255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Quá trình học và dự báo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_class=10\n",
    "y_train=np_utils.to_categorical(y_train,nb_class)\n",
    "y_test=np_utils.to_categorical(y_test,nb_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= Sequential()\n",
    "#add vào 1 lớp input,có 10 neural(10 neural) và mỗi neural có 784 input\n",
    "model.add(Dense(10,input_shape=(784,)))\n",
    "model.add(Activation('relu'))\n",
    "# add lớp hidden sẽ tự động lấy đầu vào của lớp đầu, giá trị hiden có thể thay đổi\n",
    "model.add(Dense(40))\n",
    "model.add(Activation('relu'))\n",
    "# add vào lớp đầu ra, bắt buộc là 10 vì số từ 0->9 là 10 số\n",
    "model.add(Dense(10))\n",
    "# dùng hàm softmax vì đầu ra là 10 lớp (nhận dạng số 0-9)\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics\n",
    "=['accuracy'])\n",
    "#mỗi lần lấy 128 tấm ảnh để train\n",
    "history=model.fit (x_train, y_train, batch_size = 128, epochs = 5,verbose\n",
    "= 2,validation_data = ( x_test, y_test ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"/ results /\"\n",
    "model_name = 'keras_mnist.h5'\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save (model_path)\n",
    "print( 'Saved trained model at %s ' % model_path )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot (2,1,2)\n",
    "plt.plot( history.history ['loss'])\n",
    "plt.plot( history.history['val_loss'])\n",
    "plt.title('model loss' )\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'],loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.tight_layout ()\n",
    "mnist_model = load_model(model_path)\n",
    "loss_and_metrics = mnist_model.evaluate( x_test, y_test, verbose = 2 )\n",
    "print( \"Test Loss\" , loss_and_metrics [0])\n",
    "print( \"Test Accuracy\" , loss_and_metrics[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hàm này được viết ngoài hàm main\n",
    "def load_image(filename):\n",
    " # load tấm ảnh lên\n",
    "    img = load_img(filename, grayscale=True, target_size=(28, 28))\n",
    " # chuyển về dạng vector\n",
    "    img=img_to_array(img)\n",
    " # reshape into a single sample with 1 channel\n",
    "    img=img.reshape(1,784)\n",
    "    img=img.astype('float32')\n",
    " #chuẩn hóa dữ liệu về 0-1\n",
    "    img=img/255.0\n",
    "    return img\n",
    "#load tấm ảnh cần dự báo\n",
    "Image_test = load_image('so2.JPG')\n",
    "#dự báo tấm ảnh này là số mấy\n",
    "digit = mnist_model.predict(image_test)\n",
    "print('Du bao day la so:',digit[0].argmax())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predicted_classes=mnist_model.predict(x_test)\n",
    "plt.rcParams['figure.figsize']=(9,9)\n",
    "for i in range(9):\n",
    " plt.subplot(3,3,i+1)\n",
    " num=random.randint(0,len(x_test))\n",
    " plt.imshow(x_test[num].reshape(28,28),cmap='gray',interpolation=None)\n",
    " plt.title('Class {}'.format(predicted_classes[num].argmax()))\n",
    "plt.tight_layout() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BÀI TẬP LÀM THÊM:\n",
    "NHẬN DẠNG CHỮ VIẾT TAY VỚI THƢ VIỆN TENSORFLOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Mô tả dữ liệu MNIST cho bài toán nhận dạng chữ viết tay:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels,real_values = mnist.train.next_batch(10)\n",
    "print(\"list of values loaded\",real_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels,real_values = mnist.train.next_batch(10)\n",
    "print(\"list of values loaded\",real_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.reshape(pixels[1,:],[28,28])\n",
    "plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Quá trình học và dự báo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "training_epochs = 25\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "# tf Graph Input\n",
    "x = tf.placeholder(\"float\", [None, 784]) # mnist data image of shape 28*28=784\n",
    "y = tf.placeholder(\"float\", [None, 10]) # 0-9 digits recognition => 10 classes\n",
    "# Create model\n",
    "# Set model weights\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "evidence = tf.matmul(x, W) + b\n",
    "# Construct model\n",
    "activation = tf.nn.softmax(evidence) # Softmax\n",
    "# Minimize error using cross entropy\n",
    "cross_entropy = y*tf.log(activation)\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(cross_entropy,reduction_indices=1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "#Plot settings\n",
    "avg_set = []\n",
    "epoch_set=[]\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    " sess.run(init)\n",
    " # Training cycle\n",
    " for epoch in range(training_epochs):\n",
    "     avg_cost = 0.\n",
    " total_batch = int(mnist.train.num_examples/batch_size)\n",
    " # Loop over all batches\n",
    " for i in range(total_batch):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    " sess.run(optimizer, feed_dict={x: batch_xs, y: batch_ys})\n",
    " avg_cost += sess.run(cost, feed_dict={x: batch_xs, y: batch_ys})/total_batch\n",
    " if epoch % display_step == 0:\n",
    "    print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(\n",
    "avg_cost))\n",
    " avg_set.append(avg_cost)\n",
    " epoch_set.append(epoch+1)\n",
    " print(\"Training phase finished\")\n",
    " plt.plot(epoch_set,avg_set, 'o', label='Logistic Regression Trainingphase')\n",
    " plt.ylabel('cost')\n",
    " plt.xlabel('epoch')\n",
    " plt.legend()\n",
    " plt.show()\n",
    " # Test model\n",
    " correct_prediction = tf.equal(tf.argmax(activation, 1), tf.argmax(y,1))\n",
    " # Calculate accuracy\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "print(\"Model accuracy:\", accuracy.eval({x: mnist.test.images, y: mnist.test.labels}))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
